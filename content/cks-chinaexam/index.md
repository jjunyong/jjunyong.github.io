---
emoji: ğŸ§¢
title: '[CKS] ì‹¤ì œ ê¸°ì¶œ' 
date: '2023-11-24 00:00:00'
author: jjunyong
tags: k8s
categories: DevOps
---

## 1. Kube-bench ë¬¸ì œ 
ë¬¸ì œì—ì„œ kube-benchë¥¼ ì‹¤í–‰ í›„ ë„ì¶œë˜ëŠ” ì•„ë˜ ì·¨ì•½ì ì— ëŒ€í•´ì„œ ì¡°ì¹˜í•˜ë¼ëŠ” ë¬¸ì œ
- kube api server ì·¨ì•½ì 
  - Ensure --authorization-mode argument is not set to AlwaysAllow
  - Ensure --authorization-mode includes Node, RBAC
  - Ensure --insecure-bind-address argument is not set
- kubelet ì·¨ì•½ì 
  - Ensure anonymous-auth argument is set to false
  - Ensure --authorization-mode argument is not set to AlwaysAllow
- etcd ì·¨ì•½ì 
  - Ensure --client-cert-auth argument is set to true

### ì •ë‹µ
- kube api server ì¡°ì¹˜ 
  - `--authorization-mode=Node,RBAC` ë¡œ ì„¤ì •
  - `--insecure-bind-address=0.0.0.0` ë¡œ ë˜ì–´ ìˆëŠ” í–‰ ì‚­ì œ
- kubelet ì¡°ì¹˜ 
  - /var/lib/kubelet/config.yaml íŒŒì¼ì—ì„œ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •
    - anonymous-auth falseë¡œ ì„¤ì •
      ```
      authentication:
        anonymous:
          enabled: false
      ```
    - authorization-mode Webhookìœ¼ë¡œ ì„¤ì •
      ```
        authorization:
          mode: Webhook
      ```
  - `systemctl daemon-reload`, `systemctl restart` í•´ì£¼ê¸°
- etcd ì¡°ì¹˜
  - /etc/kubernetes/manifests/etcd.yamlì—ì„œ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •
    - `--client-cert-auth=true`

## 2. ServiceAccount ë¬¸ì œ
Your organization's security policies include:
- serviceaccount does not automatically mount API credentials
- serviceaccount name must end with "-sa"

Listing file `/cs/sa/pod1.yaml`. The pod specified in yaml cannot be scheduled due to an error specified in serviceaccount.

Please complete the project:
- 1. Create new serviceaccount named `backend-sa` in the existing namespace `qa` to ensure that this serviceaccount does not automatically mount API credentials.
- 2. Use `/cs/sa/pod1.yaml` to create a pod
- 3. Finally, clean up any unused serviceaccounts in namespace `qa`

### ì •ë‹µ
- 1. `k create sa backend-sa -n qa --dry-run=client -o yaml > 2.yaml`
- 2. 2.yamlì— ì•„ë˜ì™€ ê°™ì´ automountServiceAccountTokenë§Œ ì¶”ê°€í•´ì£¼ê³  apply 
  ```
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: backend-sa
    namespace: qa
  automountServiceAccountToken: false 
  ```
- 3. /cs/sa/pod1.yamlì„ vië¡œ ì—´ê³  serviceAccountNameë§Œ backend-saë¡œ ìˆ˜ì • í›„ apply
- 4. k get pod -o yaml -n qa | grep "serviceAccount:" ë¥¼ í•´ì„œ ì¡°íšŒë˜ì§€ ì•ŠëŠ” serviceaccount ì¸ test01ì„ ì‚­ì œí•œë‹¤.

## 3. Network Policy
A default-deny network policy avoids accidentally exposing a pod in a namespace that does not define any other Networkpolicy.
<br>
Create a new default DenyPolicy named `denypolicy` in namespace `testing` for all traffic of type ingress+Egress.

- This new NP must deny all Ingress+Egress traffic in namespace `testing`.
- The newly created default Deny network policy application is matched to all pods running in namespace testing. 

### ì •ë‹µ
- ê¸°ë³¸ NP ë§Œë“¤ê¸°
  - ê³µì‹ docì—ì„œ default denyì— ëŒ€í•œ í…œí”Œë¦¿ ê°€ì ¸ì™€ì„œ nameê³¼ namespace ë§Œ ì§€ì •í•´ì£¼ë©´ë¨ 
    ```
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: denypolicy
        namespace: testing
      spec:
        podSelector: {}
        policyTypes:
        - Ingress
        - Egress
    ```

## 4. RBAC
The role bound to the pod's serviceaccount grants over-loose permission. Complete the following item to reduce the permission set.

An existing Pod named `web-pod` is already running in namespace `db`.
Edit the existing Role bound to the serviceaccount `service-account-web` to allow only get operations on resource type of services.
Create a role `role-2` in namespace `db` and only allow new role to perform delete operations on resource type of namespaces.
Create a new RoleBinding named `role-2-binding`. Bind the newly created Role to the Pod's serviceaccount

Note: Do not delete existing rolebinding

### ì •ë‹µ
- `service-account-web`ê³¼ boundë˜ì–´ ìˆëŠ” `role-1`ì„ services ë§Œ getí•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •í•œë‹¤. ( k edit role )
- `db` namespaceì— `role-2`ë¥¼ ìƒì„±í•˜ê³  namepsacesë§Œ deleteí•  ìˆ˜ ìˆë„ë¡ ìƒì„±í•œë‹¤.
- `role-2-binding`ì´ë¼ëŠ” ìƒˆë¡œìš´ rolebindingì„ ìƒì„±í•˜ì—¬ `role-2`ì™€ `service-account-web`ì„ ì—°ê²°ì‹œí‚¨ë‹¤.
  - `k create rolebinding role-2-binding --role=role-2 --serviceaccount=service-account-web -n d`

## 5. K8S audit
Enable audit logging in cluster. To do this, enable the log backend and ensure that:
- The logs are stored in /var/log/kubernetes/audit-logs.txt
- Logs file can be retained for 10days
- Retain up to 2 old audit log files

/etc/kubernetes/logpolicy/sampolepolicy.yaml provides the basic strategy. It specifies only what is not recorded.
Note: The base policy is located on the master node of the cluster.

Edit and expand basic strategies to record: 
- RequestResponse level, persistentvolumes change
- configmaps change to request body in namespace `front-apps`
- Changes to configmap and secret in all namespaces at the metadata level

In addition, add a comprehensive rule to record all other requests at the Metadata level.
Note: Dont' forget to apply the modified policy.  
### ì •ë‹µ
- kube-apiserverì˜ yamlíŒŒì¼ì„ ë°±ì—…í•´ë‘ê³  audit enable ë° ì„¤ì •ì„ ë¬¸ì œëŒ€ë¡œ ì§„í–‰í•œë‹¤. 
  ```yaml
    - --audit-policy-file=/etc/kubernetes/logpolicy/samplepolicy.yaml
    - --audit-log-path=/var/log/kubernetes/audit-logs.txt
    - --audit-log-maxage=10
    - --audit-log-maxbackup=2
  ```
- kube-apiserver yamlíŒŒì¼ì—ì„œ volumesê³¼ volumeMountë¥¼ ì„¤ì •í•œë‹¤. 
  ```yaml
  volumeMounts:
    - mountPath: /etc/kubernetes/logpolicy/samplepolicy.yaml
      name: audit
      readOnly: true
    - mountPath: /var/log/kubernetes/
      name: audit-log
      readOnly: false
  ```

  ```yaml
  volumes:
  - name: audit
    hostPath:
      path: /etc/kubernetes/logpolicy/samplepolicy.yaml
      type: File

  - name: audit-log
    hostPath:
      path: /var/log/kubernetes/
      type: DirectoryOrCreate
  ```
- ì´ì™€ ê°™ì´ ì„¤ì • í›„ kube-apiserverê°€ ì•ˆ ëœ° ìˆ˜ ìˆìŒ `systemctl daemon-reload`, `sytemctl restart kubelet`ë¥¼ í•´ì£¼ì–´ì•¼ í•¨
- ë§ˆì§€ë§‰ìœ¼ë¡œ `tail /var/log/kubernetes/audit-logs.txt` ëª…ë ¹ìœ¼ë¡œ ì •ìƒì  auditingë˜ëŠ” ì§€ ê²€ì¦í•œë‹¤. 

- basic strategyë¡œ ì£¼ì–´ì§„ yaml íŒŒì¼ì— 3ê°€ì§€ record ìš”êµ¬ì¡°ê±´ì— í•´ë‹¹ í•˜ëŠ” ì •ì±…ë“¤ì„ docì„ ì°¸ê³ í•˜ì—¬ ì¶”ê°€í•œë‹¤. 
  ```yaml
      - level: RequestResponse
        resources:
        - group: ""
          resources: ["persistentvolumes"]
      - level: Metadata
        resources:
        - group: "" # core API group
          resources: ["secrets", "configmaps"]
      - level: Request
        resources:
        - group: "" # core API group
          resources: ["configmaps"]
        namespaces: ["kube-system"]

  ```
  - ë‹¨, ë§ˆì§€ë§‰ì— catch-all ruleê¹Œì§€ ì¶”ê°€í•´ì£¼ì–´ì•¼ ì •ë‹µì´ë‹¤. 
    ```yaml
    # A catch-all rule to log all other requests at the Metadata level.
    - level: Metadata
      # Long-running requests like watches that fall under this rule will not
      # generate an audit event in RequestReceived.
      omitStages:
        - "RequestReceived"
    ```

## 6. Create a Secret
Get the contents of an existing secret named `db1-test` in namespace `istio-system`
Store the username field in the name `/cs/sec/user.txt` file and store the password in `/cs/sec/pass.txt` file.

Note : Do not use or modify created files in the following steps, you can create new temporary files if needed.

Create a new secret named `db2-test` in `istio-system` namespace as follows:
```
username: production-instance
password: KvLftKgs4aVH
```

Finally, create a new pod, it can access secret `db2-test` via volume
- name : `secret-pod`
- namespace: `istio-system`
- container name: `dev-container`
- image : `nginx`
- volume name: `secret-volume`
- mounting path: `/etc/secret`

### ì •ë‹µ
- `db1-test1` secretì—ì„œ username, passwordë¥¼ ì¶”ì¶œ í›„ base64ë¡œ ë””ì½”ë”©ëœ ê²°ê³¼ë¥¼ ê°ê°ì˜ íŒŒì¼ì— ì €ì¥í•œë‹¤.
  - `k get secret db1-test -n istio-system -o=jsonpath='{.data.username}' | base64 -d > /cs/sec/user.txt`
  - `k get secret db1-test -n istio-system -o=jsonpath='{.data.password}' | base64 -d > /cs/sec/pass.txt`
- `db2-test` secret ìƒì„±í•˜ê¸° 
  - `kubectl create secret generic db2-test -n istio-system --from-literal=username=production-instance --from-literal=password=KvLftKgs4aVH`
- podì— `db2-test` ì„ secret ë¬¸ì œì˜ ì¡°ê±´ëŒ€ë¡œ volume mountí•˜ì—¬ ìƒì„±í•˜ê¸°
  - ì•„ë˜ì™€ ê°™ì´ ì‘ì„± í›„ apply
  ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: secret-pod
      namespace: istio-system
    spec:
      containers:
      - name: dev-container
        image: nginx
        volumeMounts:
        - name: secret-volume
          mountPath: "/etc/secret"
          readOnly: true
      volumes:
      - name: secret-volume
        secret:
          secretName: db2-test
  ```

## 7. Dockerfile
- Analyze and edit the given Dockerfile `/cks/docker/dockerfile` ( based on ubuntu: 16.04 image ), and fix two instructions that have prominent security/best practices issues in the file
- Analyze and edit the given manifest file `/cs/docker/deployment.yaml`
  and fix two fields that have prominent security/best practices issues in the file

  > Note: Do not add or remove configuration settings. simply modify the existing configuration settings so that there is no more secruity/best real money problem with both of the above existing settings.

  > Note: If you need a non-privileged user to exeute any project, please use the user `nobody` with user ID `65535`, just modify it, no need to create it.


### ì •ë‹µ
- 1. /cks/docker/dockerfile ë¶€í„° ì‚´í´ë³´ê¸°
    - `FROM ubuntu:latest` -> `FROM ubuntu:16.04`ë¡œ ìˆ˜ì •
    - 2ë²ˆì§¸ USER ë¥¼ root -> nobodyë¡œ ë³€ê²½
    - `sudo docker build .`
- 2. /cs/docker/deployment.yaml ì‚´í´ë³´ê¸°
  - podìª½ì˜ labelì„ deploymentì˜ selector.matchLabelsì— ë§ê²Œ ìˆ˜ì • 
    - run: couchdb -> app: couchdbë¡œ ìˆ˜ì •
  - securityContextì˜ capability ë‚´ì—­ ì¤‘ 'CAP_SYS_ADMIN'ì„ ì‚­ì œ

## 8. gVisor
The cluster uses containerd as the CRI runtime. containerd's default runtime handler is runc.
container is ready to support additional runtime handler runsc `gVisor`

- Create a RuntimeClass named `untrusted` using an existing runtime handler named `runsc`.
Update all pods in namespace `server` to run on gVisor. 
<br>
You can do this at /cks/gVisor/rc. Find a list of templates in yaml

### ì •ë‹µ
- runtimeclass ìƒì„±
  ```yaml
  apiVersion: node.k8s.io/v1
  kind: RuntimeClass
  metadata:
    name: untrusted
  handler: runsc
  ```
- `server` namespace ë‚´ì— ëª¨ë“  deploymentì„ edití•˜ì—¬ runtimeclass ì„¤ì •
  - spec.template.spec.runtimeClassNameì„ ì„¤ì •
  - k edit deploy busybox-run -n server 
    ```yaml
      spec:
        runtimeClassName: untrusted ## ì´í–‰ ì¶”ê°€
    ```
## 9. Container security
### 9-1. 
Best practice is to design containers as stateless and immutable.

- Check the pods running in namespace `production` and remove any non-stateless or immutable pods.
- Use the following strict interpretations of statelessness and immutability.
  - A container of pods capable of storing data within a container must be considered stateless.
  - Privileged pods configured to be of any kind must be considered stateless and immutable.

### ì •ë‹µ
- privileged : trueë¡œ ì„¤ì •ëœ podì™€ hostPathë¡œ volumeì´ ì¡íŒ podë¥¼ ëª¨ë‘ ì‚­ì œí•œë‹¤. 

### 9-2.
Modify the deployment `secdep` in the `sec-ns` namespace as follows:
- First, start the container with a user id of 30000 
- Second, do not allow a process to get privileges beyond its parent process ( allowPrivilegeEscalation is prohibited )
- Third, load the container's root file system in a read-only manner( read-only permission to the root file )

### ì •ë‹µ
- k edit deploy secdep -n sec-ns ë¥¼ í•´ì„œ 
  - podë ˆë²¨ì—ì„œ ì„¤ì • :  `spec.securityContext.runAsUser: 30000`ìœ¼ë¡œ ì„¤ì •
  - ì¡´ì¬í•˜ëŠ” ëª¨ë“  ì»¨í…Œì´ë„ˆì— ëŒ€í•´ ì•„ë˜ ë‚´ìš© ì„¤ì •
    - ì»¨í…Œì´ë„ˆ ë ˆë²¨ì—ì„œ ì„¤ì • :  `spec.containers.securityContext.allowPrivilegeEscalation: false` ë¡œ ì„¤ì •
    - ì»¨í…Œì´ë„ˆ ë ˆë²¨ì—ì„œ ì„¤ì • :  `spec.containers.securityContext.readOnlyRootFilesystem: true`ë¡œ ì„¤ì • 

## 10. Network policy
Create a NetworkPolicy called `pod-restriction` to restrict access to pod `product-service` running in namepsace `dev-team`.
Allow only the following pods to connect to `product-service` pod
- All pod from namespace `qaqa`
- pod with label `environment:testing` located in any namespace

### ì •ë‹µ
ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±í•˜ë©´ ëœë‹¤. from ì ˆì´ 2ê°œ ìˆìœ¼ë©´ 2ê°œ ì¡°ê±´ì´ or ë˜ê³ , fromì ˆ í•˜ë‚˜ì— 2ê°œì˜ ì¡°ê±´ì´ ë“¤ì–´ê°€ë©´ ì¡°ê±´ì´ ì„œë¡œ andì²˜ë¦¬ë˜ëŠ” ê²ƒìœ¼ë¡œ ì´í•´í•˜ë©´ ë¨. 
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: pod-restriction
  namespace: dev-team
spec:
  podSelector:
    matchLabels:
      environment: testing
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: qaqa
    - from:
       - namespaceSelector: {}
         podSelector:
           matchLabels:
             environment: testing
```
## 11. Trivy 
Detect severely vulnerable images used by pods in namespace `kamino` using the Trivy open source container scanner
Find images with High and Critical serverity vulnerabilities and remove pods that use these images
- Note: Trivy is installed only on the master node of the cluster and is not available on the working node.
You have to switch to the master node of the cluster to use Trivy. 

### ì •ë‹µ
- kamino namespaceì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  podì˜ Image ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
- `trivy image --severity HIGH,CRITICAL {ì´ë¯¸ì§€ëª…}` ìœ¼ë¡œ vulnerableí•œ ì´ë¯¸ì§€ ì°¾ì•„ì„œ í•´ë‹¹ pod ì‚­ì œ 

## 12. Apparmor
Apparmor is enabled on `node02` of the cluster's working node. The platform apparmor configuration file already exists, but has not been implemented. 
<br>
On `node02` of the cluster, implementation is located in /etc/apparmor.d/nginx_apparmor is existing Apparmor configuration file. 
- Edit in `/cs/KSSH00401/nginx-deploy.yaml` file to apply the apparmor configuration file.
- Finally, apply the mmanifest file and create the pod specified it. 
<br>

  > Please note that during the test, apparmor is indicated on the working node, so you need to ssh to the working node written at the beginning. 
  > In an analog environment, you need ssh to node02 to work. 

### ì •ë‹µ
- 1. ssh to node02
- 2. `apparmor_parser -q /etc/apparmor.d/nginx_apparmor`
  - profileëª… ì•Œì•„ë‚´ê³  aa-statusë¡œ í•´ë‹¹ profile ì˜ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
- 3. `/cs/KSSH00401/nginx-deploy.yaml`ì˜ deployment definition íŒŒì¼ì—ì„œ podì˜ annotationì— `container.apparmor.security.beta.kubernetes.io/<container_name>: <profile_ref>` ë‚´ìš© ì¶”ê°€
- 4. k apply -f /cs/KSSH00401/nginx-deploy.yaml


## 13. Falco & sysdig
Use the runtime detction tool to detect frequency generation and execution exception selections in a single pod `tomcat123` container.
<br>
Use the tool to analyze for at least 30 seconds. Use the filter to check the generated and executed process, write the event to the `/opt/KSR00101/incidents/summary` file, which contains the detected events, in the following format: `timestamp.uid,username,processName`.

### ì •ë‹µ
- Sysdig ì‚¬ìš© ê¶Œì¥
  - sysdig -l | grep {time, user, proc, name} ë“±ì˜ ëª…ë ¹ìœ¼ë¡œ output ì‹œ ì‚¬ìš©í•  ë³€ìˆ˜ëª…ì„ íŒŒì•…í•  ìˆ˜ ìˆìŒ
  - crictl info | grep sock 
- Falco 
  - kubectl describe tomcat123ìœ¼ë¡œ container id ì•Œì•„ë‚´ê¸° 
  - /etc/faloco/falco.yamlì—ì„œ `file_output.enabled: true`, `file_output.filename`ì˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ê¸°
    - ì—¬ê¸°ì„œ ìˆ˜ì •ì´ ë°œìƒí•˜ë©´ `daemon-reload`, `systemctl restart falco`ë¥¼ ìˆ˜í–‰í•´ì¤€ë‹¤. 
  - `%evt.time,%user.uid,%proc.name`
  - ê²°ê³¼ë¥¼ outputìœ¼ë¡œ ì„ì˜ì˜ node02 ì˜ íŠ¹ì • ê²½ë¡œì— ì¶œë ¥í•œ í›„ í•´ë‹¹ ë¡œê·¸ë¥¼ localì˜ `/opt/KSR00101/incidents/summary`ì— ë¶™ì—¬ë„£ì–´ì•¼ í•  ë“¯í•˜ë‹¤. 

## 14. TLS
strengthen kube-apiserver security configuration through TLS, requirements: 
- kube-apiserver is not allowed except version TLS13 and above. 
- Cipher suite is `TLS_AES_128_GC_SHA256`

Enhance ETCD security configuration with TLS, requirements: 
- cipher suite `TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256`

### ì •ë‹µ
- kube-apiserver ê°•í™”
  - kube-apiserver.yamlíŒŒì¼ì˜ commandì— ì•„ë˜ ë‚´ìš© 2ê°œ ì¶”ê°€
    - `- --tls-min-version=VersionTLS13`
    - `- --tls-cipher-suites=TLS_AES_128_GC_SHA256`
- etcd ê°•í™”
  - etcd.yamlíŒŒì¼ì˜ commandì— `- --ciper-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256`í–‰ ì¶”ê°€
    - kube-apiserverì™€ ë‹¬ë¦¬ 'tls-'ê°€ ì—†ìŒì— ì£¼ì˜
- `systemctl daemon-reload`, `systemctl restart kubelet`

## 15. Enabling API SERVER authentication
Kubernetes API server for cluster created by kubeadm. For testing purposes, temporary configuration allows unauthenticated and unauthorized access, granting anonymnous user `cluster-admin` access.
<br>
Reconfigure the kubernetes API server for cluster. Ensure that only authenticated  and authorized REST requests are allowed. 
- Use authorization mode 'Node, RBAC' and Access Controller 'NodeRestriction'. 
- Delete the `system:anonymous` Clusterrolebinding to clean up. 
<br>

  > Note : all kubectl configuration environments/files are also configured to use unauthenticated and unauthorized access. You don't have to change it. Note,  however, that once the cluster is secured, the configuration of kubectl will not work. You can use the cluster's original kubectl configuration file `/etc/ kubernetes/admin.conf` on the master node of the cluster. Ensure that authenticated authorization reqeusts are still allowed. 

In the simulation environment, the script to initialize this problem is b.sh 

### ì •ë‹µ
- kube-apiserver.yaml íŒŒì¼ ìˆ˜ì •í•˜ê¸°
  - `- --authorization-mode=Node,RBAC` ë¡œ ìˆ˜ì •
  - `- --enable-admission-plugins=NodeRestriction`ìœ¼ë¡œ ìˆ˜ì • 
- `system:anonymous` clusterrolbinding ì‚­ì œí•˜ê¸° 
- ìœ„ ì‘ì—…ì´ ëë‚œ ë’¤, ê·¸ëƒ¥ k get podì‹œì—” ì œí•œë˜ê³ , masterë…¸ë“œì—ì„œ `k get pod -A --kubeconfig /etc/kubernetes/admin.conf`ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ ì •ìƒì ìœ¼ë¡œ podê°€ ì¡°íšŒë˜ë©´ ì„±ê³µ

## 16. ImagePolicyWebhook : container image scanning
The container mirroring scanner is set up on the cluster, but it is not fully integrated into the cluster's configuration.
After completion, the container mirror scanner should scan and reject the use of vulnerable mirrors. 
<br>
> Note: You must complete the entire test on the matser node of the cluster, and all services and files are ready and places on that node. 
<br>
Given an incomplete configuration in directory `/etc/kubernetes/epconfig`, as well as `https://image-bouncer-webhook.default.svc:1323/image_policy` functional container image scanner.
<br>

- 1. Enable the necessary plugins to create mirror policies.
- 2. Verify the control configuration and change it to implicit deny.
- 3. Edit the configuration to correctly point to the provided HTTPS endpoint last, by trying to deploy vulnerable resources `/cks/img/web1/yaml` to test if the configuration is valid. 

### ì •ë‹µ
ì²˜ìŒì— `k apply /cks/img/web1/yaml`ë¥¼ ì‹¤í–‰í•´ë³´ë©´ podê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ê±¸ ë§‰ê³  ì‹¶ì€ê²Œ ìš°ë¦¬ì˜ ëª©ì ì´ë‹¤. í…ŒìŠ¤íŠ¸ í•œ ë’¤ì—” ë‹¤ì‹œ ì‚­ì œí•´ì£¼ì.
- `epconfig` ë””ë ‰í† ë¦¬ í•˜ìœ„ì— ë³´ë©´ ì—¬ëŸ¬ íŒŒì¼ë“¤ì´ ìˆëŠ”ë° ê·¸ ì¤‘ì— `admission_configuration.json`íŒŒì¼ì—ì„œ `imagePolicy.defaultAllow: true` ì—ì„œ `imagePolicy.defaultAllow: false`ë¡œ ìˆ˜ì •í•˜ê¸° ( 2ë²ˆ ìš”êµ¬ì‚¬í•­ )
- `epconfig` ë””ë ‰í† ë¦¬ í•˜ìœ„ì˜ kubeconfig.yamlíŒŒì¼ì—ì„œ `clusters.cluster.server`ì˜ ê°’ì´ ë¬¸ì œì— ë”°ë¥´ë©´ `https://image-bouncer-webhook.default.svc:1323/image_policy`ì—¬ì•¼ í•˜ëŠ”ë° ì„¤ì •ì´ ì•ˆë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì„¤ì •í•´ì£¼ê¸°. (3ë²ˆ ìš”êµ¬ì‚¬í•­)
- kube-apiserver ì„¤ì •í•˜ê¸°
  - `- --enable-admission-plugins=ImagePolciyWebhook`ì„ ì¶”ê°€í•´ì£¼ê¸°
  - `- --admission-control-config-file=/etc/kubernetes/epconfig/admission_configuration.json`ì„ ì„¤ì •í•´ì¤€ë‹¤.
    - ê·¸ëŸ°ë° kube-apiserver podì—ì„œ ì´ jsoníŒŒì¼ì„ ëŸ°íƒ€ì„ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” volumemìœ¼ë¡œ ë§ˆìš´íŠ¸í•´ì¤˜ì•¼ í•˜ê¸°ì— volumes, volumeMount ì„¤ì •ì„ ì¶”ê°€í•´ì¤€ë‹¤.
      ```yaml
      volumeMounts:
      - mountPath: /etc/kubernetes/epconfig
        name: epconfig
        readOnly: true
      .
      .
      .
      volumes:
      - hostPath:
          path: /etc/kubernetes/epconfig
          type: DirectoryOrCreate
        name: epconfig
      ```
  - `systemctl daemon-reload`, `systemctl restart kubelet`
- ë§ˆì§€ë§‰ìœ¼ë¡œ `k apply /cks/img/web1/yaml` ëª…ë ¹ì´ ì‹¤í–‰ ì•ˆë˜ëŠ” ê²ƒìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
